@article{AnIntroductiontoQAOA,
  url     = {https://www.cs.umd.edu/class/fall2018/cmsc657/projects/group_16.pdf},
  year    = 2018,
  month   = oct,
  title   = {An Introduction to Quantum Optimization Approximation Algorithm},
  journal = { },
  author  = {Qingfeng Wang and Tauqir Abdullah}
}

@misc{farhi2014quantumapproximateoptimizationalgorithm,
      title={A Quantum Approximate Optimization Algorithm}, 
      author={Edward Farhi and Jeffrey Goldstone and Sam Gutmann},
      year={2014},
      eprint={1411.4028},
      archivePrefix={arXiv},
      primaryClass={quant-ph},
      url={https://arxiv.org/abs/1411.4028}, 
}

@book{Nielsen_Chuang_2010,
  place     = {Cambridge},
  title     = {Quantum Computation and Quantum Information: 10th Anniversary Edition},
  publisher = {Cambridge University Press},
  author    = {Nielsen, Michael A. and Chuang, Isaac L.},
  year      = {2010}
}

@article{Wang_2018,
   title={Quantum approximate optimization algorithm for MaxCut: A fermionic view},
   volume={97},
   ISSN={2469-9934},
   url={http://dx.doi.org/10.1103/PhysRevA.97.022304},
   DOI={10.1103/physreva.97.022304},
   number={2},
   journal={Physical Review A},
   publisher={American Physical Society (APS)},
   author={Wang, Zhihui and Hadfield, Stuart and Jiang, Zhang and Rieffel, Eleanor G.},
   year={2018},
   month=feb }

@misc{farhi2015quantumapproximateoptimizationalgorithm,
      title={A Quantum Approximate Optimization Algorithm Applied to a Bounded Occurrence Constraint Problem}, 
      author={Edward Farhi and Jeffrey Goldstone and Sam Gutmann},
      year={2015},
      eprint={1412.6062},
      archivePrefix={arXiv},
      primaryClass={quant-ph},
      url={https://arxiv.org/abs/1412.6062}, 
}

@misc{farhi2019quantumsupremacyquantumapproximate,
      title={Quantum Supremacy through the Quantum Approximate Optimization Algorithm}, 
      author={Edward Farhi and Aram W Harrow},
      year={2019},
      eprint={1602.07674},
      archivePrefix={arXiv},
      primaryClass={quant-ph},
      url={https://arxiv.org/abs/1602.07674}, 
}

@article{Wecker_2016,
   title={Training a quantum optimizer},
   volume={94},
   ISSN={2469-9934},
   url={http://dx.doi.org/10.1103/PhysRevA.94.022309},
   DOI={10.1103/physreva.94.022309},
   number={2},
   journal={Physical Review A},
   publisher={American Physical Society (APS)},
   author={Wecker, Dave and Hastings, Matthew B. and Troyer, Matthias},
   year={2016},
   month=aug }

@article{Jiang_2017,
   title={Near-optimal quantum circuit for Grover’s unstructured search using a transverse field},
   volume={95},
   ISSN={2469-9934},
   url={http://dx.doi.org/10.1103/PhysRevA.95.062317},
   DOI={10.1103/physreva.95.062317},
   number={6},
   journal={Physical Review A},
   publisher={American Physical Society (APS)},
   author={Jiang, Zhang and Rieffel, Eleanor G. and Wang, Zhihui},
   year={2017},
   month=jun }

@article{Harrigan_2021,
   title={Quantum approximate optimization of non-planar graph problems on a planar superconducting processor},
   volume={17},
   ISSN={1745-2481},
   url={http://dx.doi.org/10.1038/s41567-020-01105-y},
   DOI={10.1038/s41567-020-01105-y},
   number={3},
   journal={Nature Physics},
   publisher={Springer Science and Business Media LLC},
   author={Harrigan, Matthew P. and Sung, Kevin J. and Neeley, Matthew and Satzinger, Kevin J. and Arute, Frank and Arya, Kunal and Atalaya, Juan and Bardin, Joseph C. and Barends, Rami and Boixo, Sergio and Broughton, Michael and Buckley, Bob B. and Buell, David A. and Burkett, Brian and Bushnell, Nicholas and Chen, Yu and Chen, Zijun and Ben Chiaro and Collins, Roberto and Courtney, William and Demura, Sean and Dunsworth, Andrew and Eppens, Daniel and Fowler, Austin and Foxen, Brooks and Gidney, Craig and Giustina, Marissa and Graff, Rob and Habegger, Steve and Ho, Alan and Hong, Sabrina and Huang, Trent and Ioffe, L. B. and Isakov, Sergei V. and Jeffrey, Evan and Jiang, Zhang and Jones, Cody and Kafri, Dvir and Kechedzhi, Kostyantyn and Kelly, Julian and Kim, Seon and Klimov, Paul V. and Korotkov, Alexander N. and Kostritsa, Fedor and Landhuis, David and Laptev, Pavel and Lindmark, Mike and Leib, Martin and Martin, Orion and Martinis, John M. and McClean, Jarrod R. and McEwen, Matt and Megrant, Anthony and Mi, Xiao and Mohseni, Masoud and Mruczkiewicz, Wojciech and Mutus, Josh and Naaman, Ofer and Neill, Charles and Neukart, Florian and Niu, Murphy Yuezhen and O’Brien, Thomas E. and O’Gorman, Bryan and Ostby, Eric and Petukhov, Andre and Putterman, Harald and Quintana, Chris and Roushan, Pedram and Rubin, Nicholas C. and Sank, Daniel and Skolik, Andrea and Smelyanskiy, Vadim and Strain, Doug and Streif, Michael and Szalay, Marco and Vainsencher, Amit and White, Theodore and Yao, Z. Jamie and Yeh, Ping and Zalcman, Adam and Zhou, Leo and Neven, Hartmut and Bacon, Dave and Lucero, Erik and Farhi, Edward and Babbush, Ryan},
   year={2021},
   month=feb, pages={332–336} }

@article{Zhou_2020,
   title={Quantum Approximate Optimization Algorithm: Performance, Mechanism, and Implementation on Near-Term Devices},
   volume={10},
   ISSN={2160-3308},
   url={http://dx.doi.org/10.1103/PhysRevX.10.021067},
   DOI={10.1103/physrevx.10.021067},
   number={2},
   journal={Physical Review X},
   publisher={American Physical Society (APS)},
   author={Zhou, Leo and Wang, Sheng-Tao and Choi, Soonwon and Pichler, Hannes and Lukin, Mikhail D.},
   year={2020},
   month=jun }

@misc{pichler2018quantumoptimizationmaximumindependent,
      title={Quantum Optimization for Maximum Independent Set Using Rydberg Atom Arrays}, 
      author={Hannes Pichler and Sheng-Tao Wang and Leo Zhou and Soonwon Choi and Mikhail D. Lukin},
      year={2018},
      eprint={1808.10816},
      archivePrefix={arXiv},
      primaryClass={quant-ph},
      url={https://arxiv.org/abs/1808.10816}, 
}

@article{Pagano_2020,
   title={Quantum approximate optimization of the long-range Ising model with a trapped-ion quantum simulator},
   volume={117},
   ISSN={1091-6490},
   url={http://dx.doi.org/10.1073/pnas.2006373117},
   DOI={10.1073/pnas.2006373117},
   number={41},
   journal={Proceedings of the National Academy of Sciences},
   publisher={Proceedings of the National Academy of Sciences},
   author={Pagano, Guido and Bapat, Aniruddha and Becker, Patrick and Collins, Katherine S. and De, Arinjoy and Hess, Paul W. and Kaplan, Harvey B. and Kyprianidis, Antonis and Tan, Wen Lin and Baldwin, Christopher and Brady, Lucas T. and Deshpande, Abhinav and Liu, Fangli and Jordan, Stephen and Gorshkov, Alexey V. and Monroe, Christopher},
   year={2020},
   month=oct, pages={25396–25401} }

@article{Grange_2023,
   title={An introduction to variational quantum algorithms for combinatorial optimization problems},
   volume={21},
   ISSN={1614-2411},
   url={http://dx.doi.org/10.1007/s10288-023-00549-1},
   DOI={10.1007/s10288-023-00549-1},
   number={3},
   journal={4OR},
   publisher={Springer Science and Business Media LLC},
   author={Grange, Camille and Poss, Michael and Bourreau, Eric},
   year={2023},
   month=jul, pages={363–403} }

@inproceedings{Stein_2023,
   series={GECCO ’23 Companion},
   title={Evidence that PUBO outperforms QUBO when solving continuous optimization problems with the QAOA},
   url={http://dx.doi.org/10.1145/3583133.3596358},
   DOI={10.1145/3583133.3596358},
   booktitle={Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
   publisher={ACM},
   author={Stein, Jonas and Chamanian, Farbod and Zorn, Maximilian and Nüßlein, Jonas and Zielinski, Sebastian and Kölle, Michael and Linnhoff-Popien, Claudia},
   year={2023},
   month=jul, collection={GECCO ’23 Companion} }

@article{Salehi_2022,
   title={Unconstrained binary models of the travelling salesman problem variants for quantum optimization},
   volume={21},
   ISSN={1573-1332},
   url={http://dx.doi.org/10.1007/s11128-021-03405-5},
   DOI={10.1007/s11128-021-03405-5},
   number={2},
   journal={Quantum Information Processing},
   publisher={Springer Science and Business Media LLC},
   author={Salehi, \"{O}zlem and Glos, Adam and Miszczak, Jaros{\l}aw Adam},
   year={2022},
   month=jan }

@misc{he2015deepresiduallearningimage,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1512.03385}, 
}

@misc{wah_2023_cvm3y-5hh21,
      author       = {Wah, Catherine and
                        Branson, Steve and
                        Welinder, Peter and
                        Perona, Pietro and
                        Belongie, Serge},
      title        = {The Caltech-UCSD Birds-200-2011 Dataset},
      month        = aug,
      year         = 2023,
      publisher    = {California Institute of Technology},
      version      = {Published},
}

@misc{zhong2017randomerasingdataaugmentation,
      title={Random Erasing Data Augmentation}, 
      author={Zhun Zhong and Liang Zheng and Guoliang Kang and Shaozi Li and Yi Yang},
      year={2017},
      eprint={1708.04896},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1708.04896}, 
}

@misc{chen2024gridmaskdataaugmentation,
      title={GridMask Data Augmentation}, 
      author={Pengguang Chen and Shu Liu and Hengshuang Zhao and Xingquan Wang and Jiaya Jia},
      year={2024},
      eprint={2001.04086},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2001.04086}, 
}

@misc{ioffe2015batchnormalizationacceleratingdeep,
      title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}, 
      author={Sergey Ioffe and Christian Szegedy},
      year={2015},
      eprint={1502.03167},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1502.03167}, 
}

@misc{szegedy2015rethinkinginceptionarchitecturecomputer,
      title={Rethinking the Inception Architecture for Computer Vision}, 
      author={Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
      year={2015},
      eprint={1512.00567},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1512.00567}, 
}

@article{10.5555/2627435.2670313,
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
title = {Dropout: a simple way to prevent neural networks from overfitting},
year = {2014},
issue_date = {January 2014},
publisher = {JMLR.org},
volume = {15},
number = {1},
issn = {1532-4435},
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different "thinned" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {1929–1958},
numpages = {30},
keywords = {regularization, neural networks, model combination, deep learning}
}

@inproceedings{10.5555/2986916.2987033,
author = {Krogh, Anders and Hertz, John A.},
title = {A simple weight decay can improve generalization},
year = {1991},
isbn = {1558602224},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {It has been observed in numerical simulations that a weight decay can improve generalization in a feed-forward neural network. This paper explains why. It is proven that a weight decay has two effects in a linear network. First, it suppresses any irrelevant components of the weight vector by choosing the smallest vector that solves the learning problem. Second, if the size is chosen right, a weight decay can suppress some of the effects of static noise on the targets, which improves generalization quite a lot. It is then shown how to extend these results to networks with hidden layers and non-linear units. Finally the theory is confirmed by some numerical simulations using the data from NetTalk.},
booktitle = {Proceedings of the 5th International Conference on Neural Information Processing Systems},
pages = {950–957},
numpages = {8},
location = {Denver, Colorado},
series = {NIPS'91}
}

@misc{chu2022qmlperrortolerantnonlinearquantum,
      title={QMLP: An Error-Tolerant Nonlinear Quantum MLP Architecture using Parameterized Two-Qubit Gates}, 
      author={Cheng Chu and Nai-Hui Chia and Lei Jiang and Fan Chen},
      year={2022},
      eprint={2206.01345},
      archivePrefix={arXiv},
      primaryClass={cs.ET},
      url={https://arxiv.org/abs/2206.01345}, 
}
